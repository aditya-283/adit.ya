---
title: Using BERT for multi-class classification
position: 50
selected: true
languages: Ruby
tags: NLP, Transformer, Transfer Learning
description: Using BERT for multi-class classification
image: BERT.png
view_url: https://colab.research.google.com/drive/1OnpXriRyRc9IQvm5LThD0R1PBtpQc9zf#scrollTo=MYWzeGSY2xh3
call_to_action: View on Colab
---

What is remarkable about transformers is that they were the first to make transfer learning possible for language tasks, which, until then had been limited to some areas in computer vision. Here, I attempt to train a BERT network on just over 6000 training examples on the task of identifying the industry to which a company belongs based on a textual description of its business. [View on Colab](https://colab.research.google.com/drive/1OnpXriRyRc9IQvm5LThD0R1PBtpQc9zf#scrollTo=MYWzeGSY2xh3)