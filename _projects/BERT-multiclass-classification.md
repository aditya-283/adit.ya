---
title: Using BERT for multi-class classification
position: 50
selected: true
languages: Ruby
tags: NLP, Transformer, Transfer Learning
description: Using BERT for multi-class classification
image: BERT.png
view_url: https://colab.research.google.com/drive/1OnpXriRyRc9IQvm5LThD0R1PBtpQc9zf#scrollTo=MYWzeGSY2xh3
call_to_action: View on Colab
---

Transformers are remarkable because they were the first to make transfer learning possible for language tasks, which, until then had been limited to some areas in computer vision. Here I attempt to train a BERT on just 6000 odd examples to be able to identify the industry to which a company belongs based on a description of its business.